{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "November 23, 2019\n",
    "\n",
    "If the installation was done properly on October 26, we are ready to start machine learning projects.\n",
    "In the following weeks, we'll make a team and pick a project that you are interested in. In order to give you better ideas and understand what AI can do, we'll go over a few examples drawn from engineering and science. \n",
    "\n",
    "Today, let's continue our Keras programming with image denoising using autoencoder.\n",
    "We'll use the dataset that we previously played with for our number recognition and plotting. So the data should be in your cloned repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if tensorflow.__version__ < '2.0.0':\n",
    "    import keras \n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout\n",
    "\n",
    "elif tensorflow.__version__ >= '2.0.0':\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout\n",
    "      \n",
    "print(\"using tensorflow \", tensorflow.__version__)\n",
    "## keras functions are well documented in the Keras Documentaion \n",
    "## https://keras.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest3D = np.load('xtest.pickle', allow_pickle=True)\n",
    "YtestAll = np.load('ytest.pickle', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain3D = np.load('xtrain.pickle', allow_pickle=True)\n",
    "#Ytrain = np.load('ytrain.pickle', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original images have unsigned integer from 0 to 255 (8bit representation of gray scale color) \n",
    "## Since the convolutions are numerical computation, we change the data type to float32 and then \n",
    "## perform normalizations to [0,1] range\n",
    "\n",
    "Xtest3D = Xtest3D.astype('float32')/255.\n",
    "#Xtrain3D = Xtrain3D.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in order to conform to the shape of inputs to Conv2D\n",
    "## Conv2D expects 4D array\n",
    "## 1st index - sample index\n",
    "## 2nd index - image x\n",
    "## 3rd index - image y\n",
    "## 4th index - channel (Ex. RGB values in color images)\n",
    "\n",
    "Xtest4D = Xtest3D.reshape((*Xtest3D.shape, 1))\n",
    "#Xtrain = Xtrain3D.reshape((*Xtrain3D.shape, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since the computing power and time is limitted, let's reduce the size of training and test datasets \n",
    "\n",
    "Xtrain = Xtest4D[0:600,:]\n",
    "Xtest = Xtest4D[1000:1100,:]\n",
    "\n",
    "Ytrain = YtestAll[0:600]\n",
    "Ytest  = YtestAll[1000:1100]\n",
    "\n",
    "## Let's create noisy input data\n",
    "\n",
    "XtrainNoisy = Xtrain + 0.2*np.random.randn(*Xtrain.shape)\n",
    "XtestNoisy = Xtest + 0.2*np.random.randn(*Xtest.shape)\n",
    "\n",
    "XtrainNoisy = np.clip(XtrainNoisy, 0., 1.)\n",
    "XtestNoisy = np.clip(XtestNoisy, 0., 1.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain.shape\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's plot one of them\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(6,3))\n",
    "\n",
    "fig.suptitle('MNIST figure %d'%(Ytrain[5]), fontsize=18)\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "ax[0].imshow(Xtrain[5,:,:,0], cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "\n",
    "ax[1].imshow(XtrainNoisy[5,:,:,0], cmap='gray')\n",
    "ax[1].set_title('Noisy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's check the shape and type of the our test dataset\n",
    "\n",
    "print(Xtest.shape)\n",
    "print(Xtest.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.shape)\n",
    "print(Xtrain.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's define our neural network model that consists of Convolutional, Flattening, MaxPooling and UpSampling layers\n",
    "## We can go deep into each layers and optimization if necessary and if our members are interested.\n",
    "\n",
    "def model(choice = 2):\n",
    "    '''\n",
    "    input parameters\n",
    "      choice - 1, classification of mnist handwriting images\n",
    "               2, encoding and decoding for denoising\n",
    "               \n",
    "    output\n",
    "      keras model defining the network from an input to the final output\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    input_img = Input(shape=(28, 28, 1))\n",
    "    x1 = Conv2D(32, (3,3), activation='relu', padding='same')(input_img)\n",
    "    x2 = MaxPooling2D((2,2), padding='same')(x1)\n",
    "    x3 = Conv2D(32, (3,3), activation='relu', padding='same')(x2)\n",
    "    \n",
    "    encoded = MaxPooling2D((2,2), padding='same')(x3)\n",
    "    c1 = Flatten()(encoded)\n",
    "    c2 = Dense(128, activation='relu')(c1)\n",
    "    c3 = Dropout(0.2)(c2)\n",
    "    \n",
    "    ## this is the final output for classification\n",
    "    classifierOutput = Dense(10, activation='softmax')(c3)\n",
    "    \n",
    "    ## The following layers from y4 to decoded is for denoising\n",
    "    ## we'll cover this in the next meeting\n",
    "    y4 = Conv2D(32, (3,3), activation='relu', padding='same')(encoded)\n",
    "    y3 = UpSampling2D((2,2))(y4)\n",
    "    y2 = Conv2D(32, (3,3), activation='relu', padding='same')(y3)\n",
    "    y1 = UpSampling2D((2,2))(y2)\n",
    "    \n",
    "    decoded = Conv2D(1, (3,3), activation='sigmoid', padding='same')(y1)\n",
    "    \n",
    "    if choice == 1:\n",
    "        return Model(input_img, classifierOutput)\n",
    "    elif choice == 2: \n",
    "        ## This part is for the next meeting\n",
    "        return Model(input_img, decoded)    \n",
    "    else:\n",
    "        return Model(inputs=[input_img], outputs=[classifierOutput, decoded])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we call a function and get our model defintion.\n",
    "mydenoiser = model(2)  ## model(1) -classification, model(2) - denoising, model (0) - both\n",
    "mydenoiser.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Once a model is defined, we need to configure the model for trainging \n",
    "## by selecting optimizer and loss function\n",
    "\n",
    "mydenoiser.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the traing stage that is compute intensive and may require high performance computers\n",
    "## or GPU machines if the size of the training dataset is huge\n",
    "## \n",
    "## In the begining of notebook, we decimated the size of the training dataset to finish our meeting on time\n",
    "## If you increase the epochs, the number of data repetition,\n",
    "## the running time will increase linearly proportional to the epochs.\n",
    "mydenoiser.fit(XtrainNoisy, Xtrain, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpred = mydenoiser.predict(XtestNoisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydenoiser.evaluate(XtestNoisy, Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtestNoisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showNumbers(Xdata):\n",
    "    numpic = 10\n",
    "    plt.figure(figsize=(12,4))\n",
    "    for i in range(numpic):\n",
    "        ax = plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(Xdata[i, :, :, 0])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showNumbers(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showNumbers(XtestNoisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showNumbers(Xpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
